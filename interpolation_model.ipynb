{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3533f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08cf1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Read corpus from txt file\n",
    "def read_corpus(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        corpus = file.read()\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4662870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split corpus into training, validation, and testing subsets\n",
    "\n",
    "def split_corpus(corpus):\n",
    "    sentences = nltk.sent_tokenize(corpus)\n",
    "    total_length = len(sentences)\n",
    "    train_end = int(total_length * 0.7)\n",
    "    val_end = int(total_length * 0.1)\n",
    "    \n",
    "    train_set = sentences[:train_end]\n",
    "    val_set = sentences[train_end:train_end+val_end]\n",
    "    test_set = sentences[train_end+val_end:]\n",
    "    \n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bbffb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Preprocess corpus\n",
    "def preprocess_corpus(corpus):\n",
    "    # Remove special characters, keep only full stops and remove stop words\n",
    "    processed_corpus = re.sub(r'[^\\w\\s.]', '', corpus)\n",
    "    processed_corpus = re.sub(r'\\b\\w{1,3}\\b', '', processed_corpus)\n",
    "    return processed_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8f21835",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Tokenize corpus and limit vocabulary size\n",
    "def tokenize_corpus(corpus, vocab_size):\n",
    "    tokens = word_tokenize(corpus)\n",
    "    token_counts = Counter(tokens)\n",
    "    vocab = {token for token, count in token_counts.most_common(vocab_size)}\n",
    "    tokenized_corpus = [token if token in vocab else '<UNK>' for token in tokens]\n",
    "    return tokenized_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a42609f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Build 4-gram language model with add-k smoothing and LM2 interpolation\n",
    "def build_language_model(tokens, k, vocab_size, lambdas):\n",
    "    ngrams = nltk.ngrams(tokens, 4, pad_left=True, pad_right=True)\n",
    "    bigrams = nltk.ngrams(tokens, 2, pad_left=True, pad_right=True)\n",
    "    trigrams = nltk.ngrams(tokens, 3, pad_left=True, pad_right=True)\n",
    "\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    trigram_counts = Counter(trigrams)\n",
    "    ngram_counts = Counter(ngrams)\n",
    "\n",
    "    def calculate_probability(wi_minus_2, wi_minus_1, wi):\n",
    "        lambda1, lambda2, lambda3 = lambdas\n",
    "\n",
    "        prob_4gram = (ngram_counts[(wi_minus_2, wi_minus_1, wi, wi)] + k) / \\\n",
    "                      (trigram_counts[(wi_minus_2, wi_minus_1, wi)] + k * vocab_size)\n",
    "\n",
    "        prob_3gram = (trigram_counts[(wi_minus_1, wi, wi)] + k) / \\\n",
    "                      (bigram_counts[(wi_minus_1, wi)] + k * vocab_size)\n",
    "\n",
    "        prob_2gram = (bigram_counts[(wi, wi)] + k) / \\\n",
    "                      (trigram_counts[(wi, wi)] + k * vocab_size)\n",
    "\n",
    "        return lambda1 * prob_4gram + lambda2 * prob_3gram + lambda3 * prob_2gram\n",
    "\n",
    "    return calculate_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d34b798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Evaluate models on test set using perplexity\n",
    "def evaluate_model(model, test_tokens):\n",
    "    total_log_prob = 0\n",
    "    N = len(test_tokens)\n",
    "    for i in range(2, N-2):\n",
    "        wi_minus_2, wi_minus_1, wi, wi_plus_1 = test_tokens[i-2:i+2]\n",
    "        prob = model(wi_minus_2, wi_minus_1, wi)\n",
    "        total_log_prob += -1 * (prob * (N-4))\n",
    "    perplexity = 2 ** (total_log_prob / N)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5224aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_text(model, seed_text, length, vocab):\n",
    "    generated_text = seed_text\n",
    "    seed_tokens = seed_text.split()  # Split seed text into tokens\n",
    "    for i in range(length):\n",
    "        wi_minus_2, wi_minus_1 = seed_tokens[-2:]\n",
    "        next_token_probabilities = {}\n",
    "        for token in vocab:\n",
    "            next_token_probabilities[token] = model(wi_minus_2, wi_minus_1, token)\n",
    "        \n",
    "        # Apply nucleus sampling\n",
    "        sorted_tokens = sorted(next_token_probabilities.keys(), key=lambda x: next_token_probabilities[x], reverse=True)\n",
    "        sorted_probs = [next_token_probabilities[token] for token in sorted_tokens]\n",
    "        sorted_cum_probs = np.cumsum(sorted_probs)\n",
    "        sorted_cum_probs /= sorted_cum_probs[-1]\n",
    "        \n",
    "        # Choose next token using nucleus sampling\n",
    "        sampled_token_index = np.argmax(sorted_cum_probs > np.random.rand())\n",
    "        next_token = sorted_tokens[sampled_token_index]\n",
    "\n",
    "        if next_token == '<UNK>':\n",
    "            # Replace <UNK> token with a randomly selected word from the vocabulary\n",
    "            next_token = np.random.choice(list(vocab))\n",
    "        \n",
    "        generated_text += ' ' + next_token\n",
    "        seed_tokens.append(next_token)\n",
    "        if next_token == '.':\n",
    "            break\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91c9cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read corpus\n",
    "corpus = read_corpus('khmer_food.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e08cc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split corpus\n",
    "train_set, val_set, test_set = split_corpus(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fd3a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess corpus\n",
    "processed_train_set = preprocess_corpus(' '.join(train_set))\n",
    "processed_val_set = preprocess_corpus(' '.join(val_set))\n",
    "processed_test_set = preprocess_corpus(' '.join(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd539940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize corpus\n",
    "vocab_size = 5000\n",
    "train_tokens = tokenize_corpus(processed_train_set, vocab_size)\n",
    "val_tokens = tokenize_corpus(processed_val_set, vocab_size)\n",
    "test_tokens = tokenize_corpus(processed_test_set, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b6d3f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build language model\n",
    "k_values = [0.1, 0.01, 0.001]\n",
    "lambdas = [(0.1, 0.3, 0.6), (0.2, 0.4, 0.4), (0.3, 0.5, 0.2)]  # example lambdas\n",
    "best_perplexity = float('inf')\n",
    "best_k = None\n",
    "best_lambdas = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25995efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for k=0.1, lambdas=(0.1, 0.3, 0.6): 0.959424022136948\n",
      "Perplexity for k=0.1, lambdas=(0.2, 0.4, 0.4): 0.9594406310429467\n",
      "Perplexity for k=0.1, lambdas=(0.3, 0.5, 0.2): 0.9594572402364677\n",
      "Perplexity for k=0.01, lambdas=(0.1, 0.3, 0.6): 0.9597219031294116\n",
      "Perplexity for k=0.01, lambdas=(0.2, 0.4, 0.4): 0.9598848507556724\n",
      "Perplexity for k=0.01, lambdas=(0.3, 0.5, 0.2): 0.9600478260482069\n",
      "Perplexity for k=0.001, lambdas=(0.1, 0.3, 0.6): 0.9621672806091125\n",
      "Perplexity for k=0.001, lambdas=(0.2, 0.4, 0.4): 0.9635405992464016\n",
      "Perplexity for k=0.001, lambdas=(0.3, 0.5, 0.2): 0.9649158780460423\n",
      "Best k: 0.1\n",
      "Best lambdas: (0.1, 0.3, 0.6)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "for k in k_values:\n",
    "    for lambdas_value in lambdas:  # Updated variable name here\n",
    "        model = build_language_model(val_tokens, k, vocab_size, lambdas_value)  # Pass lambdas_value to build_language_model\n",
    "        perplexity = evaluate_model(model, val_tokens)\n",
    "        print(f\"Perplexity for k={k}, lambdas={lambdas_value}: {perplexity}\")  # Print perplexity for each parameter combination\n",
    "        if perplexity < best_perplexity:\n",
    "            best_perplexity = perplexity\n",
    "            best_k = k\n",
    "            best_lambdas = lambdas_value  # Updated variable name here\n",
    "\n",
    "print(\"Best k:\", best_k)\n",
    "print(\"Best lambdas:\", best_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5e3a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set perplexity: 0.9116703579908271\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "best_model = build_language_model(train_tokens, best_k, vocab_size, best_lambdas)\n",
    "test_perplexity = evaluate_model(best_model, test_tokens)\n",
    "print(\"Test set perplexity:\", test_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5b7f897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.build_language_model.<locals>.calculate_probability(wi_minus_2, wi_minus_1, wi)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0babc6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: This is khmer savory clear commonly Cambodias under squeezing tenderizes kdam mushrooms root overnight banh soft even snack live juice nectarines Gnoam best which preference break unique Rasmi speciality consistency countryside been filled region much steak overcooking infuses thinly cucumbers choosing vegetables Souls best Womens hearty result friends included .\n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "seed_text = \"This is khmer\"\n",
    "vocab =set(train_tokens)\n",
    "generated_text = generate_text(best_model, seed_text, 1000, vocab)\n",
    "print(\"Generated text:\", generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
